


  {
  
  
    "properties" : {},
  
  "type" : "lab",
  "title" : "Lab-10",
  "img" : "img/main.png",
  "videoid" : "none",
  "objectives" : "<p>More Excel - binary classification </p>",
  "folder" : "book",
  "link" : "index.html",
  "los": [
   ]
,
  "chapters" : [
  
    {
    "title": "#Objectives",
    "shortTitle": "Lab-10",
    "contentMd" : "#Objectives\r\n\r\nMore Excel - binary classification \r\n\r\nNotes developed using material produced by Daniel Egger from Duke University. Copyright Daniel Egger/ Attribution 4.0 International (CC BY 4.0)"
    },
  
    {
    "title": "#Binary Classification",
    "shortTitle": "01",
    "contentMd" : "#Binary Classification\r\n\r\nBinary classification is the process of determining the classification of something with either a positive or a negative.\r\n\r\nThis methodology dates from the 1940's when decisions had to be made based on radar signals whether to send up fighter pilots or not. The cost of a false positive was the burning of aviation fuel, and exhausting the pilots. The cost of false negative could have catastrophic consequences.\r\n\r\nThe methodology known as receiver operating characteristic curve or ROC curve was developed for this purpose. The curve itself allowed decision makers to choose when to make a positive classification based on their best estimate for the cost of making a false positive and a false negative. Maximising the area under the ROC curve is a good measure of the power of a binary classification model to discriminate signal from noise that is still used.\r\n\r\n\r\nIn the following example we have two conditions, the radar signal either indicates Bombers or Seagulls. We also have two classifications called Positive (send up the fighters) and Negative (do nothing).\r\n\r\nThis produces a 2*2 grid with four possible classifications and conditions. It is traditional to locate the actual condition to the left of the grid, thus showing (+) for bombers and (-) for seagulls below. The same for the classification at the top, a positive one to the left, negative to the right. This allows us to label the four squares on the grid as True Positive, False Positive, False Negative, True Negative.\r\n\r\nThis is called the confusion matrix:\r\n\r\n![](./img/01.png)\r\n\r\nIn this example the ROC curve works in that each radar image is assigned a numerical score that corresponds to the actual area of the blur on the radar screen.\r\n\r\n![](./img/02.png)\r\n\r\nThe actual condition wheather it is a bomber or a seagull is also tracked. After data is collected, pairs of scores and actual conditions are placed in ranked order from highest to lowest score.\r\n\r\nFighter command could determine that no image on the radar justified a positive classification, thus every classification would be negative.\r\nAlternatively they could decide that every image on the radar justified a positive classification, thus every classification would be positive.\r\n\r\nIn reality the threshold between positive and negative classifications is always set somewhere in between those two extremes, the threshold usually depends on the cost of false classifications.\r\n\r\nA False positive \"rate\" is the total number of false positive classifications, divided by the total number of seagulls.\r\nA True positive \"rate\" is the total number of true positive classifications, divided by the total number of bombers.\r\n\r\n\r\nThe ROC curve is drawn by identifying for a given threshold, its false positive rate and its true positive rate then plot these points where the x and y axis meet. The x axis is the false positive rate and y axis is the true positive rate. Plot these coordinates for each threshold between  the highest and the lowest scores. Summing the area beneath the curve gives the Area Under the Curve (AUC)\r\n\r\n![](./img/03.png)\r\n"
    },
  
    {
    "title": "#Confusion Matrix",
    "shortTitle": "02",
    "contentMd" : "#Confusion Matrix\r\n\r\nWhen we have binary outcomes and a binary classification, we can be right in two different ways and we can be wrong in two different ways.\r\n\r\nWhen we correctly classify an event as positive this is known as a True Positive.\r\nWhen we correctly classify an event as negative this is known as a True Negative.\r\n\r\nHow can we achieve a good result, while minimizing the errors?\r\nWhen we incorrectly classify an event as positive this is known as a False Positive.\r\nWhen we incorrectly classify an event as negative this is known as a False Negative (perhaps the biggest error).\r\n\r\nSo in our situation with our bombers and seagulls, we have 20 observations, of which 3 turned out to be bombers and 17 were seagulls. In terms of the numerical rating the 3 bombers are shown in red and the seagulls in black.\r\n\r\nWhen the ratings are ranked the 3 bombers are not all at the top, they appear at 92, 83 and 75. If they were all at the top it would make the job of setting the threshold very easy but that's not the case.\r\n\r\n![](./img/04.png)\r\n\r\nWe could decide to put our threshold at 80. We would have two true positives (83 and 93) and one false negative (75). Or we could put it at 70 and have three true positives and no false negatives. However how many false positives would we have? We want to avoid sending our planes up when actually it is just a seagull! If we stuck with a threshold of 70 we would have 7 false positives.\r\n\r\nUsing the confusion matrix we can populate the four boxes for the chosen threshold.\r\n\r\nAt a threshold of 80 we would have the following:\r\n\r\n2 true positives\r\n1 false negative\r\n4 false positives\r\n13 true negatives\r\n\r\n\r\nAt the threshold of 80 our matrix looks like this:\r\n\r\n![](./img/05.png)\r\n\r\nWhat would happen if our threshold was at 70?\r\n\r\nOur binary classifications system involves something that generates ratings that can be turned into rankings to which we can apply a threshold. Everything below the threshold is negative and everything above the threshold is positive.\r\n"
    },
  
    {
    "title": "#Optimal Threshold",
    "shortTitle": "03",
    "contentMd" : "#Optimal Threshold\r\n\r\nThe typical way that we characterize a particular threshold is by its false positive rate and its true positive rate.\r\n\r\nA false positive rate is the number of false positives divided by the total number of negatives.\r\nThe true positive rate is the opposite, the number of true positives divided by the total number of positives.\r\n\r\nAt a threshold of 80 we would have the following:\r\n\r\n- 2 true positives\r\n- 1 false negative\r\n- 4 false positives\r\n- 13 true negatives\r\n\r\n![](./img/05.png)\r\n\r\nIn this we have a total of 17 negatives, 13 that were true and 4 that were false positives.\r\n\r\nIt has a false positive rate of 4 divided by 17.\r\n\r\nIn this case 2 true positives divided by the total positives which is 3. Therefore it has a true positive rate of 2/3rds.\r\n\r\n\r\nAnd at our threshold of 70,\r\n\r\n![](./img/06.png)\r\n\r\nHas a false positive range of 7/17ths, but it has a true positive range of one (3/3).\r\n\r\nEach ordered pair where x is equal to the false positive rate, y is equal to the true positive rate.\r\n\r\n- x=  FP rate\r\n- y = TP rate\r\n\r\nevery threshold has it's corresponding point on the plot.\r\n\r\nEach of these points can be plotted on an x y coordinate plane, and so every threshold has its corresponding point. So the threshold of 80 would have the point 4/17ths, so that's a little bit less than a quarter and two thirds, 4/17ths, 2/3rds and 7/17ths 1.\r\n\r\nSo, this is a representation of\r\n\r\nThe false positive rates and the true positive rates, at all possible thresholds.\r\n\r\n![](./img/03.png)\r\n\r\nIt shows at each threshold the intersection between false positive and true positive rates.\r\n\r\nAnd the shaded area is called the area under the curve.\r\n\r\nWhich in the case of our example is equal to .82 (more on this in our next lab).\r\n\r\nWhich is quite a reasonable, decent rate for a diagnostic or for any kind of tool that's trying to discriminate between two states.\r\n\r\nHow much it's actually going to cost us, our cost function, is dependent upon the cost for each mistake.\r\n\r\nSo generally, False negative mistakes are very expensive, Bombers get through and they destroy a lot of things.\r\n\r\nThen False positive mistakes are also expensive, we sent up a bunch of planes and we used up fuel and we also had the risk that our planes were one place where bombers might be somewhere else.\r\n\r\nWe will see when we work with some quiz problems and with Excel spreadsheets that where you put your threshold is going to be determined by the relative size of these two costs.\r\n\r\nSo in a situation where bombers getting through is hugely expensive relative to the cost of sending up planes. Then you really, really want the smallest possible number of False Negatives here.\r\n\r\nThus we're willing to go for a lower threshold.\r\n"
    },
  
    {
    "title": "#Calculating Positive and Negative Predictive Values",
    "shortTitle": "04",
    "contentMd" : "#Calculating Positive and Negative Predictive Values\r\n\r\nNow we will use another example of binary classification, this one is a typical distribution for a cancer diagnostic. It is a protein blood test that identifies a rare cancer. It has an incidence rate of 1% in the population we are studying. This means individuals getting the blood test have a 1% chance of having the cancer and 99% of not.\r\n\r\nThis test would be considered a good test because:\r\n\r\nIts true positive rate is 95% (true positives divided by actual incidence of condition).\r\nand\r\nIts true negative rate is 80% (true negatives divided by the incidence of not having the condition).\r\n\r\n![](./img/07.png)\r\n\r\n\r\nIf you come to the doctors office and get a positive test result you might be alarmed if you had been told the test has a true positive rate of 95%.\r\n\r\nThe true positive rate is the conditional probability of having a positive test where I do have cancer.\r\n\r\nP(positive test/+ cancer)\r\n\r\nThe true negative rate is the conditional probability of having a negative test where I don't have cancer.\r\nP(negative test/- cancer)\r\n\r\nThat isn't really what we want to know.\r\n\r\nWhat we want to know is:\r\n\r\n- What is the conditional probability of having the condition having received a positive blood test?\r\n\r\n~~~\r\n\r\nPositive Predictive Value\r\n\r\nP(+ cancer/ positive test)\r\n\r\n~~~\r\n\r\n- What is the probability of us not having the condition when we receive a negative blood test?\r\n\r\n~~~\r\n\r\nNegative Predictive Value\r\n\r\nP(- cancer/ negative test)\r\n\r\n~~~\r\n\r\nThe way we calculate these is to use the true positive value divided by the total number of positive classifications.\r\n\r\n![](./img/09.png)\r\n\r\n~~~\r\nPositive predictive value\r\n\r\n.0095/.2075 = 4.58%\r\n~~~\r\n\r\nI have a 4.58% chance of having cancer.\r\n\r\n~~~\r\n\r\nNegative predictive value\r\n\r\n.792/.7925 = 99.937%\r\n\r\n~~~\r\n\r\nI have a 99.937% chance of not having cancer.\r\n"
    }
  
  ]
  }

