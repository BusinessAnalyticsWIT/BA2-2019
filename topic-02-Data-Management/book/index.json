


  {
  
  
    "properties" : {},
  
  "type" : "lab",
  "title" : "Lab-02",
  "img" : "img/main.png",
  "videoid" : "none",
  "objectives" : "<p>Refining research questions is essential in order to focus your analysis and discover the answer to a specific well thought out research question.</p>",
  "folder" : "book",
  "link" : "index.html",
  "los": [
   ]
,
  "chapters" : [
  
    {
    "title": "#Refining your research question by selecting rows",
    "shortTitle": "Lab-02",
    "contentMd" : "#Refining your research question by selecting rows\r\n\r\nRefining research questions is essential in order to focus your analysis and discover the answer to a specific well thought out research question.\r\n"
    },
  
    {
    "title": "#Solution",
    "shortTitle": "01",
    "contentMd" : "#Solution\r\n\r\nThe solution python file for lab01 is available here\r\n\r\n- [lab1 python file](./archives/lab01.py)\r\n\r\nIf you did not get the lab finished copy the code and save it to your working directory and run it to make sure it works.\r\n\r\nAs you learn more keep applying it to your continuous assessment.\r\n\r\n##Selecting rows\r\n\r\nOnce you examine frequency distributions for your variables you need to decide whether you want to look at a subset of the data.\r\n\r\nFor example so far we have conducted frequency distributions on the entire data set or sample so our question concerning the association between smoking and nicotine dependence has been applied to the full sample.\r\n\r\nWe now can decide to examine only those adults who are 25 or younger and exclude all adults older than the age of 25. We also decide we want to focus on recent smokers, rather than individuals who smoked more than a year ago.\r\n\r\nThe research question has not changed. Rather, the question will be asked based on only a subset of the observations that are available in a specific dataset that will help us answer our research question.\r\n\r\nTo implement these decisions we will add additional code to our program.\r\n\r\nFirst you should \"save as\" the Lab01.py file and call it Lab02.py still saving it in your working directory.\r\n\r\nWe will need to add logic statements that tell the program to include only those observations that will help you answer your research question.\r\n\r\nLogic statements require one or more operations. Here are common operators used in Python, you should be familiar with these from the DataCamp or Codecademy Python course you started in Week 3.\r\n\r\nHere are the common ones used in Python:\r\n\r\n![](./img/00.png)\r\n\r\nThese include equal to, not equal to, less than, greater than, less than or equal to, and greater than or equal to.\r\n\r\nOur code needs to include three logic statements in order to include in the specified observations (rows) from our dataset.\r\n\r\n~~~\r\n\r\nage >= 18  and  age <=25 and smoker in last 12 months = yes\r\n\r\n~~~\r\n\r\nTo do this we must place this logic in our Python code. First we must check in our code book to see what variable names we need to use for analysing age and recent smoker.\r\n\r\nPage 5 in the code book shows us a variable called AGE that contains a number representing the age in years of each respondent. You may recall in Lab02 we used a variable called CHECK321 which was the cigarette smoking status where the value 1 indicated the respondent smoked within the last 12 months.\r\n\r\nYou can see that is it very important to have a well documented code book to support your analysis.\r\n\r\nThe code we need to add to our program is shown below:\r\n\r\n~~~\r\nprint('The number of rows in the subset of adults between 18 and 25 that have smoked in the past 12 months')\r\nsubset1 = nesarc_data[(nesarc_data['AGE']>=18) & (nesarc_data['AGE']<=25) & (nesarc_data['CHECK321']=='1')]\r\nprint(len(subset1))\r\n\r\n~~~\r\n\r\nIf you remember in Lab04 we converted two variables to numbers using pandas.to_numeric. The logic statement above tests the value in CHECK321 is equal to the string '1'. If you converted CHECK321 to a number also then the logic statement will have to compare the CHECK321 variable value to the number 1\r\n\r\n\r\nRemember we have to tell Python within each part of the logic statement what dataset we are working on and each variable name is held in quotation marks and square brackets.\r\nEach logic statement is enclosed in parenthesis and separated with in this case an 'and' symbol &. Finally the logic is contained with the square brackets.\r\n\r\nSave and run the program. You should at the end of the console the following output:\r\n\r\n![](./img/01.png)\r\n\r\nNext write the code to generate distribution frequencies for the Age variable in the new subset1\r\n\r\n\r\nYour code should look like this:\r\n\r\n![](./img/02.png)\r\n\r\nYour output like this:\r\n\r\n![](./img/03.png)\r\n\r\nRemember the output is only for the 1706 individuals between the ages of 18 and 25 who reported smoking in the past 12 months.\r\n\r\nAs a check to make sure you are working on the subset you can check the count for the variable CHECK321 and there should only be 1706 for the value 1.\r\n\r\n![](./img/04.png)\r\n\r\n\r\n\r\n##Tips\r\n\r\nIt is often useful to make a copy of a dataframe it is easily done using the following code:\r\n\r\n~~~\r\nsubset2=subset1.copy()\r\n~~~\r\n\r\nThen you can use subset2. This can cause issues when dealing with datatypes that were converted however.\r\nSometimes if you want to do comparisons on a variable in the copy the data conversion we did in lab04 on the nesarc_data does not copy over to the subset. It just means you have to apply that conversion again to the subset. (see the next step)\r\n\r\n~~~\r\nprint('Number of observations in subset 2')\r\nprint(len(subset2))\r\n~~~\r\n\r\n![](./img/05.png)\r\n"
    },
  
    {
    "title": "#Data Management",
    "shortTitle": "02",
    "contentMd" : "#Data Management\r\n\r\nData Management involves making decisions about recording data in ways that help to answer our research questions.\r\n\r\nThe code book and frequency distributions often are the first port of call for helping to make these decisions. You will use both of these tools often because they reveal things about the data that will be helpful to you.\r\n\r\n[nesarc codebook](./archives/NESARC_codebook.pdf)\r\n\r\nThere are several steps commonly considered when conducting your data management. In some cases the dataset is very clean and the variables are already well managed that you do not need to do much if any data management.\r\n\r\nIn all datasets you should consider each possible decision you make about a dataset. This means you play an active role in understanding your data and assuring that you are asking your questions in an appropriate and meaningful way, as well as ensuring your treatment of the data and changes you make are documented and justified.\r\n\r\n##Missing Data\r\n\r\nA first step to consider is whether or not you need to code out missing data.\r\n\r\nFor example the adult smoker from step1. In the Nesarc codebook you can see the response of 1 in variable S3AQ3B1 is for daily smoking. The data will often include response categories that don't help you answer your question even though they provide information. For instance, in this variable we have a response category unknown, coded as a nine.\r\n\r\nFor these responses, we don't know how much these individuals smoked and therefore we may not want to include them in our analysis.\r\n\r\nUsing the new data frame subset we created in the last step of this lab subset2 we are going to set responses of 9 for variable S3AQ3B1 to missing so that Python disregards these values. First we need make sure that the variable S3AQ3B1 in the subset2 is actually a number\r\n\r\n~~~\r\n\r\nsubset2['S3AQ3B1']=pandas.to_numeric(subset2['S3AQ3B1'])\r\n\r\n~~~\r\n\r\nif you do a frequency count on that variable you will see how many 9 values there are:\r\n\r\n~~~\r\n\r\n#counts for S3AQ3B1\r\nprint('counts for S3AQ3B1 - usual frequency when smoked cigarettes')\r\nc7= subset2[\"S3AQ3B1\"].value_counts(sort=True)\r\nprint (c7)\r\n\r\n\r\n~~~\r\n You should see there are 3 values set to 9.\r\n\r\nThen enter this code:\r\n\r\n~~~\r\n\r\nsubset2['S3AQ3B1']=subset2['S3AQ3B1'].replace(9,numpy.nan)\r\n\r\n~~~\r\n\r\nthis replaces all the 9 values in that variable with NaN using the numpy library. Nan is how Python specifies missing data.\r\n\r\nRemember when you use a variable you have to tell Python the data frame the variable is inside. So we have to include subset2 in the code.\r\n\r\nNow we check to see if there are any values equal to 9 still remaining for that variable\r\n~~~\r\n\r\nprint((subset2['S3AQ3B1']==9).sum())\r\n\r\n~~~\r\n\r\nThis should result in 0.\r\n\r\nNext we can count how many are Nan or null\r\n\r\n~~~\r\n\r\nprint(subset2['S3AQ3B1'].isnull().sum())\r\n\r\n~~~\r\n\r\nor we do our frequency distribution again for that variable:\r\n\r\n~~~\r\n\r\nprint('counts for S3AQ3B1 - usual frequency when smoked cigarettes')\r\nc8= subset2['S3AQ3B1'].value_counts(sort=True, dropna=False)\r\nprint (c8)\r\n\r\n~~~\r\n\r\nYou should see that the 3 values that were originally 9 are now Nan.\r\n"
    },
  
    {
    "title": "#Data management",
    "shortTitle": "03",
    "contentMd" : "#Data management\r\nNext consider another variable, S3AQ3C1 which holds values for the usual smoking quantity.\r\n\r\nLook up the codebook for this variable. It is a value of between 1 and 98. A value of 99 indicates an unknown response. It is this value that we want to deal with, we want to set it to missing since it doesn't measure the number of cigarettes smoked, but rather indicates that we have no information on cigarette use for individuals coded as 99.\r\n\r\nComplete the same steps as you did for S3AQ3B1.\r\n\r\nYou should see 9 observations that contained values 99 that are now set to Nan.\r\n\r\nExamine each variable that is of interest to you to manage any missing values.\r\n\r\nThe next step is deciding whether or not you need to code in valid data that has been unnecessarily set to missing.\r\n\r\nIn some data sets, particularly those based on surveys, there are often skip patterns. Skip patterns are often created in\r\nsurveys that allow participants to skip questions in which the answer can be logically determined. In this way, missing data on some questions might mean that we can reasonably recover valid information.\r\n\r\nFor the question, did you drink at least one alcoholic drink in the past 12 months (variable S2AQ3), many participants said no. These individuals would not need to be asked the question about how often they drank alcohol in the past 12 months, therefore they are empty.\r\n\r\nLook up the codebook for both of these variables so you are familiar.\r\n\r\nFirst you should count the frequencies for each variable so you can see how many are blanks.\r\n\r\n![](./img/06.png)\r\n\r\nFor this variable we need to find out first what the blank is, is it null, is it an empty string or it is a space.\r\n\r\nAn easy way to check is to do a count on the number of observations that fit a criteria:\r\n\r\nHere we can see 180 observations answered no to \"did you drink at least one alcoholic drink in the past 12 months?\" (value 2)\r\n\r\nThen we can see that 180 observations answered blank to \"How often they drank alcohol in the past 12 months?\"\r\n\r\n~~~\r\n#first see if there are any nulls\r\n\r\nprint((subset2['S2AQ8A'].isnull()).sum())\r\n\r\n#next see if there are any empty values\r\nprint((subset2['S2AQ8A']==\"\").sum())\r\n\r\n#next see if there are any that contain a space\r\nprint((subset2['S2AQ8A']==\" \").sum())\r\n\r\n\r\n~~~\r\n\r\nYou should see 180 returned for the last line of code, this tells us there are 180 observations that contain a space.\r\n\r\nWe need to replace this \" \" with NaN. So for the variable (S2AQ8A), how often did you drink alcohol in the past 12 months, it would be reasonable to code this as valid data (with the value 11) rather than missing for those saying that they have never drank alcohol.\r\n\r\n\r\nNow we want to replace the blank data with Nan.\r\n\r\n~~~\r\n\r\nsubset2['S2AQ8A']=subset2['S2AQ8A'].replace(' ', numpy.NaN)\r\n\r\n\r\n~~~\r\n\r\nNow do the same count again for the full variable to see how many there are for each value:\r\n\r\n~~~\r\n\r\nc10=subset2['S2AQ8A'].value_counts(sort=True, dropna=False)\r\nprint(c10)\r\n\r\n# or just count the nulls\r\n\r\nprint(subset2['S2AQ8A'].isnull().sum())\r\n\r\n~~~\r\n\r\nNext we want to replace the nulls with an actual value, in this case 11 (here we are adding a category to the list) We need to include if S2AQ3 is not equal to 9 to our logic statement, in order to separate the no responses\r\n\r\n~~~\r\n\r\nsubset2.loc[(subset2['S2AQ3']!=9) & (subset2['S2AQ8A'].isnull()),'S2AQ8A']=11\r\n\r\n~~~\r\n\r\nprint out the counts now for the complete variable to double check that you now have 180 observations for the value 11.\r\n"
    },
  
    {
    "title": "#Recoding responses",
    "shortTitle": "04",
    "contentMd" : "#Recoding responses\r\n\r\nAnother useful step in data management is to give your variables response codes that may be more logical than those they were originally given. For example, the variable usual smoking frequency S3AQ3B1 shows in the code book that lower values mean more smoking, and higher values means the respondents smoked less.\r\n\r\nThis coding sounds counterintuitive. We could choose to reverse code this variable so that higher values means more smoking, and lower values mean less smoking.\r\n\r\n\r\nFirst we build a dictionary that recodes each value:\r\n\r\n~~~\r\n\r\nrecode1= {1: 6, 2: 5, 3: 4, 4: 3, 5: 2, 6: 1}\r\n\r\n~~~\r\n\r\nThe format is value colon new value with commas separating each.\r\n\r\nNext we use the map function to point to point to the recode1 dictionary and ask that these new codes apply to variable S3AQ3B1\r\n\r\n~~~\r\n\r\nsubset2['USFREQ'] = subset2['S3AQ3B1'].map(recode1)\r\n\r\n~~~\r\n\r\nIn this case it is good practice to create a new variable to hold the newly coded values so that you do not get confused with the original data.\r\n\r\nIf however we wanted to recode using a more quantitative value rather than categorical (6=daily, 5=5 to 6 days per week). To do this we choose values that reasonable correspond to the number of times each individual smokes in a typical month.\r\n\r\n- So someone who reports smoking everyday could be said to smoke cigarettes 30 days in a month.\r\n- Someone who smokes 5 to 6 days a week could be said to smoke 22 days in a usual month.\r\n- Someone who smokes 3 to 4 days a week could be said to smoke 14 days in a usual month.\r\n- Those smoking 1 to 2 days a week would be five days in a usual month.\r\n- Those smoking 2 to 3 days a month would be 2.5 days in a usual month.\r\n- Once a month or less would be 1 day in a usual month.\r\n\r\nAlthough these are estimates, they capture the quantitative nature of the measure and also keep individuals ordered in terms of the frequency with which they smoke. Our new variable is named USFREQMO which stands for the number of days per month.\r\n\r\n~~~\r\n\r\nrecode2 = {1: 30, 2: 22, 3: 14, 4: 5, 5: 2.5, 6: 1}\r\n\r\nsubset2['USFREQMO'] = subset2['S3AQ3B1'].map(recode2)\r\n\r\n~~~\r\n\r\n\r\nPrint out the counts for each of the three variable to double check the frequencies are correct for S3AQ3B1, USFREQ, and USFREQMO\r\n\r\n\r\nSo this makes more sense, while it is a categorical value, we're actually getting more information out of it than we had originally been given.\r\n"
    },
  
    {
    "title": "#Exercises",
    "shortTitle": "Exercises",
    "contentMd" : "#Exercises\r\n\r\nFurther Data Management\r\n\r\nThere are many ways to tidy up your dataframe.\r\n\r\n- rename column names to readable names.\r\n- remove any columns you are not using.\r\n- print out a count the number of columns and rows.\r\n\r\n##Rename column names to readable names\r\n\r\nCreate a new python file, name it lab2Ex.py\r\n\r\nImport pandas and numpy.\r\n\r\nJust after the import statements we will list the columns that we want to use, to do this we create a dictionary to refer to when we rename and ultimately remove any other columns.\r\n\r\nA dictionary are indexed by keys, which can be any immutable type. It is best to think of a dictionary as a set of key:value pairs, with the requirement that the keys are unique (within one dictionary). A pair of braces creates an empty dictionary {}.\r\n\r\nPlacing a comma-separated list of key:value pairs within the braces adds initial key:value pairs to the new dictionary as seen below:\r\n\r\n~~~\r\n\r\n# SETUP\r\n#Columns that will be read from the CSV file and give them names that make sense\r\nnesarc_dict =  {\r\n  'TAB12MDX': 'NICOTINE_DEPENDENCE',\r\n  'CHECK321' : 'SMOKING_STATUS',\r\n   'S3AQ3B1' : 'FREQUENCY_OF_SMOKING',\r\n   'S3AQ3C1' : 'QUANTITY_SMOKED',\r\n   'S2AQ3': 'DRANK_ALCOHOL',\r\n   'S2AQ8A' : 'ALCOHOL_FREQUENCY'\r\n}\r\n\r\n~~~\r\n\r\nNext we need to read in the data from the csv filter\r\n~~~\r\n#LOAD DATA\r\nnesarc_data = pandas.read_csv(\r\n  'nesarc_pds.csv',\r\n  low_memory=False\r\n)\r\n~~~\r\n\r\n\r\nNow we can rename the columns using the dictionary to map the old name to the new name.\r\n\r\nWe use a pandas function rename with the columns option as seen below:\r\n\r\n\r\n~~~\r\n# RENAME COLUMNS\r\nprint('data read, performing rename operation')\r\nnesarc_data.rename(columns=nesarc_dict, inplace=True)\r\nprint('data fetched')\r\n\r\n#TEST THE RENAMING\r\nnesarc_data.columns\r\nprint('counts for TAB12MDX - nicotine dependence in the past 12 months, yes=1')\r\nc1= nesarc_data[\"NICOTINE_DEPENDENCE\"].value_counts(sort=True)\r\nprint (c1)\r\n~~~\r\n\r\nYou should now see the following if the renaming worked correctly:\r\n\r\n![](./img/07.png)\r\n\r\nNext we want to only keep in our nesarc dataframe the 6 columns we are working on in this lab.\r\n\r\n~~~\r\n\r\n#Update the dataframe to only contain the columns you do want to use in your analysis.\r\nnesarc_data = pandas.DataFrame(nesarc_data, columns = nesarc_dict.values())\r\nprint('new column amount: ' + str(len(nesarc_data.columns)))\r\n\r\n~~~\r\n\r\nThis should show you an output of 6 for the number of columns.\r\n\r\nSome useful properties and functions you can use on your dataframe:\r\n\r\n~~~\r\nnesarc_data.head\r\nnesarc_data.tail\r\nnesarc_data['NICOTINE_DEPENDENCE'].describe()\r\nnesarc_data.dtypes\r\n\r\n~~~\r\n\r\n\r\n\r\nApply what you have learned in this lab to your continuous assessment.\r\n"
    }
  
  ]
  }

