


  {
  
  
    "properties" : {},
  
  "type" : "lab",
  "title" : "Lab-08",
  "img" : "img/main.png",
  "videoid" : "none",
  "objectives" : "<p>Continuous Assessment conducting regression analysis</p>",
  "folder" : "book",
  "link" : "index.html",
  "los": [
   ]
,
  "chapters" : [
  
    {
    "title": "#Regression",
    "shortTitle": "Lab-08",
    "contentMd" : "#Regression\r\n\r\nContinuous Assessment conducting regression analysis\r\n"
    },
  
    {
    "title": "#Regression",
    "shortTitle": "01",
    "contentMd" : "#Regression\r\n\r\nIn lab06 you worked on hypothesis testing, this is the initial work conducted to determine relationships between variables. You worked on the association between a diagnosis of major depression and how much a person smokes.\r\n\r\nExplanatory variable MAJORDEPLIFE categorical\r\nResponse variable NUMCIGMO_EST numerical\r\n\r\nLooking back at the output for lab06 step 2 we can see the following:\r\n\r\n![](./img/09.png)\r\n\r\nA regression model can also be informative and help to predict a value.\r\nWe can now use the intercept value and the coef value to determine how many cigarettes would be smoked by someone with a diagnosis of major depression.\r\nThe linear equation is used to do this:\r\n\r\n~~~\r\ny = mx + b\r\n\r\ny = slope(x) + intercept\r\n\r\nNUMCIGMO_EST = 32.9033 (MAJORDEPLIFE) + 309.3644\r\n\r\n~~~\r\n\r\nThis tells us that when MAJORDEPLIFE contains the value of 1 indicating major depression, then the number of cigarettes smoked  will be:\r\n\r\n~~~\r\n\r\nNUMCIGMO_EST = 32.9033(1) + 309.3644\r\nNUMCIGMO_EST = 342\r\n\r\n~~~\r\n\r\nWhen MAJORDEPLIFE contains the value of 0 indicating no diagnosis of major depression, then the number of cigarettes smoked will be:\r\n\r\n~~~\r\n\r\nNUMCIGMO_EST = 32.9033(0) + 309.3644\r\nNUMCIGMO_EST = 309\r\n\r\n~~~\r\n\r\n\r\n##For this lab we will predict the number of cigarettes smoked per day if someone is diagnosed as nicotine dependent.\r\n\r\nLets look at the linear relationship between nicotine dependence and the number of cigarettes smoked per month.\r\n\r\n- The null hypothesis is nicotine dependence has no relationship with the number of cigarettes smoked per day.\r\n\r\nNicotine Dependence is a binary categorical explanatory variable, and the number of cigarettes smoked per month is a quantitative response variable.\r\n\r\nOur research question is:\r\n\r\n- Is having nicotine dependence (explanatory/categorical) associated with an increased number of cigarettes smoked (response/numerical)?\r\n\r\nOpen the following python file save aa Lab08_regression.py\r\n\r\n- [lab8 starter python file](./archives/lab8_starter.py)\r\n\r\nAt the end of this file we will add some code now to build a regression model.\r\n\r\nTake note in the code we must ensure that the variables NUMCIGMO_EST and TAB12MDX have no spaces \" \" and are in fact numerical.\r\n\r\n\r\nNext enter the following:\r\n~~~\r\n\r\n#regression for association between nicotine dependence and Number of cigarettes smoked per month\r\nprint('OLS regression model for the association between nicotine dependence and number of cigarettes smoked per month')\r\nreg1 = smf.ols('NUMCIGMO_EST ~ TAB12MDX',data=subset2).fit()\r\nprint(reg1.summary())\r\n\r\n~~~\r\n\r\n\r\nThe response variable comes before the ~ tilda.\r\n\r\n\r\n![](./img/06.png)\r\n\r\nThe name of our response variable, the number of observations with valid values in both variables.\r\nThe parameter estimates (for the line equation) and our p values are also highlighted in the image above.\r\n\r\n~~~\r\ny = mx + b\r\n\r\ny = slope(x) + intercept\r\n\r\nNUMCIGMO_EST = 152.47 (TAB12MDX) + 248.95\r\n\r\n~~~\r\n\r\n\r\nWhat does this tell us?\r\n\r\nthe variable TAB12MDX contains the value 1 if the observation is nicotine dependent and the value zero if the observation is not nicotine dependent.\r\n\r\nWe can place these values into the equation to get the number of cigarettes smoked for each group.\r\n\r\n~~~\r\n\r\nNUMCIGMO_EST = 152.47(0) + 248.95\r\nNUMCIGMO_EST = 248.95\r\n\r\nNUMCIGMO_EST = 152.47(1) + 248.95\r\nNUMCIGMO_EST = 401.42\r\n\r\n~~~\r\n\r\nOverall the model shows an F-Statistic value of 107.4 with a very small Prob (F stat) value ( that is less than our alpha value of .5 which tells us with 95% confidence that the null hypothesis is rejected) showing that the nicotine dependence does have a relationship with the number of cigarettes smoked per month and it is statistically significant.\r\n\r\n\r\nThe R-Squared value however shows that the nicotine dependence variable only accounts for 5% of the variance in the number of cigarettes smoked.\r\n\r\n\r\nThe intercept is 248.95 and is statistically significant with a p value of <.01.\r\n\r\nSmokers without nicotine dependence smoke approximately 249 cigarettes per month.\r\n\r\nSmokers with nicotine dependence smoke approximately 401 cigarettes per month.\r\n\r\nWe can support this finding with investigating the mean number of cigarettes per month for each group.\r\n\r\n~~~\r\n\r\nsubset2 = subset2[['NUMCIGMO_EST','TAB12MDX']].dropna()\r\n\r\nprint(\"Mean\")\r\nds1 = subset2.groupby('TAB12MDX').mean()\r\nprint(ds1)\r\n\r\nprint(\"STD\")\r\nds2 = subset2.groupby('TAB12MDX').std()\r\nprint(ds2)\r\n\r\n~~~\r\n\r\nWhen you see the output from this piece of code the mean for observations that are not nicotine dependent (zero value in TAB12MDX) is the same as the calculated regression equation 248.95. The same applied when TAB12MDX holds a 1 value for nicotine dependence.\r\n\r\nRemember when you calculate the mean using the groupby on a categorical variable like TAB12MDX there are only two values so it shows you the mean for 0 that is not nicotine dependent and 1 for nicotine dependent.\r\nIf you want to get the mean for a numerical variable you use the following :\r\n~~~\r\n\r\ndataframe_name['variable_name'].mean()\r\n\r\n~~~\r\n"
    },
  
    {
    "title": "#Multivariant Regression",
    "shortTitle": "02",
    "contentMd" : "#Multivariant Regression\r\n\r\nWe now have evidence that nicotine dependence is associated to the number of cigarettes smoked per month, we also know that having major depression is also associated to the number of cigarettes smoked?\r\n\r\nWe can add the categorical explanatory variable MAJORDEPLIFE, it has two values, 0 when the observation does not have major depression and 1 when the observation does.\r\n\r\nPerhaps major depression is a confounder variable and is the true reason the number of cigarettes increases.\r\n\r\nPlace the following code in before your reduced your subset2 down to only TAB12MDX and NUMCIGMO_EST.\r\n~~~\r\n\r\n#Multivariate linear regression\r\nprint('OLS regression model for the association between nicotine dependence, major depression and number of cigarettes smoked per month')\r\nreg2 = smf.ols('NUMCIGMO_EST ~ TAB12MDX + MAJORDEPLIFE',data=subset2).fit()\r\nprint(reg2.summary())\r\n\r\n\r\n~~~\r\n\r\n![](./img/07.png)\r\n\r\nLooking at the results we can see that adding the MAJORDEPLIFE variable has increased the overall prob (F statistic) value. The MAJORDEPLIFE variable also shows a p value that is > 0.05 and so is not statistically significant and the coefficient value is negative. This means we cannot reject the null hypothesis that regression model is not significant for both variables effects on number of cigarettes.\r\n\r\nHowever we can see that the nicotine dependence is still statistically significantly associated with number of cigarettes smoked having controlled for the existence of Major depression. We can conclude that Major depression is not a confounding variable in this case.\r\n\r\nIf the p value for nictotine dependence changed and was no longer < 0.05 it would mean that major depression was a confounding variable and was responsible for the association.\r\n\r\nNote: if a parameter estimate (coefficient) is negative and has a significant P value, then it means the variable has a negative association with the response variable. These are called parameter estimates because they are from our sample they are not from the complete population.\r\n\r\nFor multiple regression we can keep adding categorical explanatory variables to check for confounding variables.\r\n\r\nFor example the following shows the output from testing the association of age, gender, number of cigarettes, major depression and Dysthymia on the quantitative response variable: number of nicotine dependent symptoms.\r\n\r\n![](./img/08.png)\r\n\r\nIn this output we can see that only Major depression and number of cigarettes smoked have a statistically significant association with the number of nicotine dependent symptoms.\r\n\r\n#Centering Explanatory Variables\r\nWhere a quantitative explanatory variable is included in the model, it is necessary to centre the data. For example the age variable and number of cigarettes are quantitative and therefore each observation's age has the mean age subtracted from it and the number of cigarettes smoked for each observation has the mean number of cigarettes smoked subtracted from it, in order to include them in the model.\r\n\r\nIt is important to remember even after controlling many additional explanatory variables in our model we can not prove causation.\r\n"
    },
  
    {
    "title": "#Regression Modelling",
    "shortTitle": "03",
    "contentMd" : "#Regression Modelling\r\n\r\nCreate a new file called Lab08_ca.py\r\n\r\nThe first relationship we are going to investigate is between the explanatory variable urbanrate and the response variable internetuserate from the gapminder data set.\r\n\r\nThe null hypothesis is that urban rate has no relationship with the internet use rate.\r\nThe alternate hypothesis is that a relationship exists between urbane rate and internet use rate.\r\n\r\nThese are both quantitative variables. From our scatterplot in lab 5 you can see a relationship may exist between these variables.\r\n\r\nTo identify the strength of this relationship we use linear regression.\r\n\r\n![](./img/00.png)\r\n\r\nWe now test the model by determining the equation of the best fit line.\r\n\r\n~~~\r\ncommonly seen as:\r\ny = mx + b\r\n\r\nLinear regression equation:\r\nŶ = ß0 + ß1 * x\r\n~~~\r\n\r\nY is the response variable\r\nX is the explanatory variable\r\n\r\nb/ß0 is the intercept parameter\r\nm/ß1 is the slope parameter\r\n\r\n\r\nSimple regression is where there is only one explanatory variable\r\n\r\nIn python we use the ordinary less squares or OLS function from the stats model formula API library.\r\n\r\nPrior to doing this we must first replace any \" \" empty strings with NaN as we did before for both the urbanrate and internetuserate variables.\r\nThen we must convert both variables to_numberic so that python interprets them correctly in order to run the OLS function.\r\n\r\n![](./img/02.png)\r\n\r\nNext enter the following code to perform the linear regression.\r\n\r\n~~~\r\n\r\n#regression for association between urbandrate and internet use rate\r\nprint('OLS regression model for the association between urbanrate and internet use rate')\r\nreg1 = smf.ols('internetuserate ~ urbanrate',data=gapminder_data).fit()\r\nprint(reg1.summary())\r\n\r\n~~~\r\n\r\nLook at the output now:\r\n\r\n![](./img/01.png)\r\n\r\nDep variable shows us the name of the response variable.\r\nWe can see the number of observations that had valid data on both response and explanatory variables and we therefore included in analysis.\r\n\r\nThe top right section of the summary informs us of the significance of the overall regression model. The R-Squared value tells us the proportion of the change in the response variable that is attributed to the explanatory variable. In this case 38 of the change in internet use rate can be explained by urban rate.\r\n\r\n![](./img/05.png)\r\n\r\nThe Prob (F-statistic) value is very small, considerably less than our alpha level of 0.5 (95% confidence). This tells us that we can reject the null hypothesis and conclude that urban rate is significantly associated with internetuserate.\r\n\r\nNow we look at the parameter estimates to calculate our best fit line.\r\n\r\n![](./img/03.png)\r\n\r\n~~~\r\n\r\ny = mx + b\r\n\r\ny = slope(x) + intercept\r\n\r\ninternetuserate = .72 (urbanrate) + (-4.90 )\r\n\r\n~~~\r\n\r\nThe middle section of the summary explains the effect of the explanatory variable on the response variable. The size of the coefficient for the explanatory variable tell us the size of the effect. In this example when urbanrate goes up by 1 then internetuserate will increase by .7202\r\n\r\nLooking at the output for the coefficients there is a column labeled P>|t| . This gives us the p value for our explanatory variable's association with the response variable. The p value is 0.000 which means that it is really small and less than .05 which is the generally accepted point at which you reject the null hypothesis. Here you would report the p value as p<.0001 and thus the likelihood of these results (i.e showing a relationship between the variables) coming up in a random distribution of data is less than 5%. Conversely you can say that with 95% probability that the variable urbanrate is having some affect on internetuserate.\r\n\r\n\r\nWe can now predict the value of Y when we know the value of X\r\n\r\n\r\n- A country has 80% urbanisation, we can predict the value of y.\r\n\r\n\r\n~~~\r\n\r\nŶ = ß0 + ß1 * x\r\n\r\nß1=0.72\r\nx=80\r\nß0=-4.90\r\n\r\nŷ= -4.90 + (0.72)(80)\r\n\r\n= 52.7\r\n\r\n~~~\r\nWe would expect 52.7 people out of every 100 to use the internet.\r\n\r\nFor every one unit increase in x we would expect y to increase by .72\r\n\r\nRemember though this is the expected value that sits directly on the best fit line,  our data will differ to some extent. Expected data is not the same as observed data.\r\n\r\nThis model is limited by the fact that we impose a causal model rather than test for causation (experimental study).\r\n\r\nFor example, Canada has an urban rate of about 80%. However its Internet use rate is observed at 81.3 not 52.7, this is why we include an error term in our model. Statistics allows us to identify trends in the data, and use those trends to look at what we would expect our data to look like.\r\n\r\n\r\n##Assessment\r\nConduct the same analysis on the explanatory variable lifeexpectancy and the response variable employrate.\r\n\r\n\r\n- Write the null and alternate hypothesis in your code file (commented out)\r\n- Present the mean and std dev for both variables.\r\n- Conduct regression analysis to determine the relationship\r\n- Report on the relationship in terms of p value.\r\n- Apply your findings to discover what would the employrrate rate be for a life expectancy age of 80\r\n\r\nSubmit your files to Moodle.\r\n- Lab08_regression\r\n- Lab08_ca\r\n"
    }
  
  ]
  }

